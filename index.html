<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Survey with Live Emotion Detection</title>

  <!-- Bootstrap 5 CSS -->
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css" rel="stylesheet">
  <script defer src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>

  <style>
    body {
      background-color: #121212;
      color: #e0e0e0;
    }
    h1, p {
      text-align: center;
    }
    .card {
      background-color: #1e1e1e;
      border: 1px solid #333;
    }
    .card-header {
      background-color: #222;
      border-bottom: 1px solid #333;
      color: #ffb300;
    }
    .card-body {
      padding: 1rem;
    }
    video, canvas {
      width: 100%;
      border-radius: 8px;
      display: block;
    }
    #video-container {
      position: relative;
      width: 100%;
      background-color: black;
      border-radius: 8px;
      overflow: hidden;
    }
    canvas {
      position: absolute;
      top: 0;
      left: 0;
    }
    #log {
      background-color: #212121;
      border-left: 5px solid #ffb300;
      padding: 1rem;
      border-radius: 8px;
      font-family: monospace;
      white-space: pre-wrap;
      overflow-wrap: break-word;
      margin-top: 1rem;
      color: #ffc107;
      min-height: 150px;
    }
    iframe {
      width: 100%;
      border: none;
      border-radius: 8px;
      height: 800px;
    }
  </style>
</head>
<body>
  <div class="container py-4">
    <h1 class="mb-3">Customer Feedback Survey with Live Emotion Detection</h1>
    <p class="mb-5">
      Fill out the survey on the right while we analyze your live reactions on the left!
    </p>

    <div class="row g-4">
      <!-- Left Column: Camera + Overlay + Log -->
      <div class="col-lg-6">
        <div class="card">
          <div class="card-header">
            Live Emotion Detection
          </div>
          <div class="card-body">
            <div id="video-container">
              <video id="video" autoplay muted></video>
              <canvas id="overlay"></canvas>
            </div>
            <div id="log" class="mt-3">Initializing emotion detection...</div>
            <button id="downloadLog" class="btn btn-warning mt-2">Download Log</button>
          </div>
        </div>
      </div>

      <!-- Right Column: Google Form -->
      <div class="col-lg-6">
        <div class="card">
          <div class="card-header">
            Customer Feedback Form
          </div>
          <div class="card-body">
            <iframe 
              src="https://docs.google.com/forms/d/e/1FAIpQLSeu8jKASboCL2FuPgIR5wy-yVAi6DTsdMUpSIrsKQq51Ycw6g/viewform?embedded=true">
              Loadingâ€¦
            </iframe>
          </div>
        </div>
      </div>
    </div>
  </div>

  <!-- Bootstrap 5 JS -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js"></script>

  <!-- FaceAPI Setup and Logic -->
  <script>
    let emotionLog = [];

    async function start() {
      await faceapi.nets.tinyFaceDetector.loadFromUri('./models/tiny_face_detector_model');
      await faceapi.nets.faceExpressionNet.loadFromUri('./models/face_expression_model');

      const video = document.getElementById('video');
      const overlay = document.getElementById('overlay');
      const context = overlay.getContext('2d');
      const logDiv = document.getElementById('log');

      navigator.mediaDevices.getUserMedia({ video: true })
        .then(stream => {
          video.srcObject = stream;
        })
        .catch(err => {
          console.error(err);
          logDiv.innerText = 'Error accessing camera. Please allow webcam permissions.';
        });

      video.addEventListener('loadedmetadata', () => {
        video.play();
        overlay.width = video.videoWidth;
        overlay.height = video.videoHeight;
        analyzeLoop(video, context, logDiv);
      });

      document.getElementById('downloadLog').addEventListener('click', downloadEmotionLog);
    }

    async function analyzeLoop(video, context, logDiv) {
      setInterval(async () => {
        const detection = await faceapi
          .detectSingleFace(video, new faceapi.TinyFaceDetectorOptions())
          .withFaceExpressions();

        context.clearRect(0, 0, overlay.width, overlay.height);

        if (detection) {
          const dims = faceapi.matchDimensions(overlay, video, true);
          const resized = faceapi.resizeResults(detection, dims);
          faceapi.draw.drawDetections(overlay, resized);

          const expressions = detection.expressions;

          let filipinoEmotion = "NEUTRAL";
          const maxExpression = Object.entries(expressions).sort((a, b) => b[1] - a[1])[0];

          if (maxExpression[0] === "neutral") {
            filipinoEmotion = "NEUTRAL";
          } else if (expressions.sad > 0.4 || expressions.fearful > 0.4) {
            filipinoEmotion = "TAMPO";
          } else if (expressions.happy > 0.3 || expressions.surprised > 0.3) {
            filipinoEmotion = "KILIG";
          } else if (expressions.angry > 0.3 || expressions.disgusted > 0.3) {
            filipinoEmotion = "GIGIL";
          } else {
            filipinoEmotion = "NEUTRAL";
          }

          context.font = '20px Arial';
          context.fillStyle = 'yellow';
          context.fillText(`Detected: ${filipinoEmotion}`, 20, 40);

          const logEntry = {
            time: new Date().toLocaleTimeString(),
            filipino: filipinoEmotion
          };
          emotionLog.push(logEntry);

          logDiv.innerText = emotionLog
            .slice(-5)
            .map(entry => `[${entry.time}] ${entry.filipino}`)
            .join('\n');

        } else {
          context.font = '20px Arial';
          context.fillStyle = 'red';
          context.fillText('No face detected', 20, 40);
        }
      }, 1000);
    }

    function downloadEmotionLog() {
      if (emotionLog.length === 0) {
        alert("No logs to download yet!");
        return;
      }

      const lines = emotionLog
        .map(entry => `[${entry.time}] ${entry.filipino}`)
        .join('\n');

      const blob = new Blob([lines], { type: 'text/plain' });
      const url = URL.createObjectURL(blob);
      const a = document.createElement('a');
      a.href = url;
      a.download = `emotion_log_${new Date().toISOString()}.txt`;
      a.click();
      URL.revokeObjectURL(url);
    }

    window.addEventListener('DOMContentLoaded', start);
  </script>
</body>
</html>
<!-- End of index.html -->