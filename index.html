<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Survey with Live Emotion Detection</title>
  
  <!-- ✅ Bootstrap 5 CSS with Dark Theme -->
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css" rel="stylesheet">
  <script defer src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>

  <style>
    body {
      background-color: #121212;
      color: #e0e0e0;
    }
    h1, p {
      text-align: center;
    }
    .card {
      background-color: #1e1e1e;
      border: 1px solid #333;
    }
    .card-header {
      background-color: #222;
      border-bottom: 1px solid #333;
      color: #ffb300;
    }
    .card-body {
      padding: 1rem;
    }
    video, canvas {
      width: 100%;
      border-radius: 8px;
      display: block;
    }
    #video-container {
      position: relative;
      width: 100%;
    }
    canvas {
      position: absolute;
      top: 0;
      left: 0;
    }
    #log {
      background-color: #212121;
      border-left: 5px solid #ffb300;
      padding: 1rem;
      border-radius: 8px;
      font-family: monospace;
      white-space: pre-wrap;
      overflow-wrap: break-word;
      margin-top: 1rem;
      color: #ffc107;
    }
    iframe {
      width: 100%;
      border: none;
      border-radius: 8px;
      height: 800px;
    }
  </style>
</head>
<body>
  <div class="container py-4">
    <h1 class="mb-3">Customer Feedback Survey with Live Emotion Detection</h1>
    <p class="mb-5">
      Fill out the survey on the right while we analyze your live reactions on the left!
    </p>

    <div class="row g-4">
      <!-- ✅ Left Column: Camera + Overlay + Log -->
      <div class="col-lg-6">
        <div class="card">
          <div class="card-header">
            Live Emotion Detection
          </div>
          <div class="card-body">
            <div id="video-container">
              <video id="video" autoplay muted></video>
              <canvas id="overlay"></canvas>
            </div>
            <div id="log" class="mt-3">Initializing emotion detection...</div>
          </div>
        </div>
      </div>

      <!-- ✅ Right Column: Google Form -->
      <div class="col-lg-6">
        <div class="card">
          <div class="card-header">
            Customer Feedback Form
          </div>
          <div class="card-body">
            <iframe 
              src="https://docs.google.com/forms/d/e/1FAIpQLSeu8jKASboCL2FuPgIR5wy-yVAi6DTsdMUpSIrsKQq51Ycw6g/viewform?embedded=true">
              Loading…
            </iframe>
          </div>
        </div>
      </div>
    </div>
  </div>

  <!-- ✅ Bootstrap 5 JS (Optional, but good practice) -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js"></script>

  <script>
    let emotionLog = [];

    async function start() {
      // Load models
    await faceapi.nets.tinyFaceDetector.loadFromUri('./models/tiny_face_detector_model');
await faceapi.nets.faceExpressionNet.loadFromUri('./models/face_expression_model');


      const video = document.getElementById('video');
      const overlay = document.getElementById('overlay');
      const context = overlay.getContext('2d');
      const logDiv = document.getElementById('log');

      // Access webcam
      navigator.mediaDevices.getUserMedia({ video: true })
        .then(stream => {
          video.srcObject = stream;
        })
        .catch(err => {
          console.error(err);
          logDiv.innerText = 'Error accessing camera.';
        });

      video.addEventListener('loadedmetadata', () => {
        video.play();
        overlay.width = video.videoWidth;
        overlay.height = video.videoHeight;
        analyzeLoop(video, context, logDiv);
      });
    }

    async function analyzeLoop(video, context, logDiv) {
      setInterval(async () => {
        const detection = await faceapi
          .detectSingleFace(video, new faceapi.TinyFaceDetectorOptions())
          .withFaceExpressions();

        context.clearRect(0, 0, overlay.width, overlay.height);

        if (detection) {
          // Draw box
          const dims = faceapi.matchDimensions(overlay, video, true);
          const resized = faceapi.resizeResults(detection, dims);
          faceapi.draw.drawDetections(overlay, resized);

          // Get top expression
          const expressions = detection.expressions;
          const topExpression = Object.entries(expressions)
            .sort((a, b) => b[1] - a[1])[0][0];

          // Map to Filipino emotions
          const mapping = {
            happy: "KILIG",
            angry: "GIGIL",
            sad: "TAMPO",
            neutral: "NEUTRAL",
            surprised: "KILIG",
            fearful: "TAMPO",
            disgusted: "GIGIL"
          };

          const filipinoEmotion = mapping[topExpression] || "NEUTRAL";

          // Draw label
          context.font = '24px Arial';
          context.fillStyle = 'yellow';
          context.fillText(`Detected: ${topExpression.toUpperCase()} → ${filipinoEmotion}`, 20, 40);

          // Log
          const logEntry = {
            time: new Date().toLocaleTimeString(),
            detected: topExpression,
            filipino: filipinoEmotion
          };
          emotionLog.push(logEntry);

          // Show last 5 logs
          logDiv.innerText = JSON.stringify(emotionLog.slice(-5), null, 2);
        } else {
          context.font = '24px Arial';
          context.fillStyle = 'red';
          context.fillText('No face detected', 20, 40);
        }
      }, 1000);
    }

    window.addEventListener('DOMContentLoaded', start);
  </script>
</body>
</html>
